import streamlit as st
import requests
from bs4 import BeautifulSoup
from transformers import pipeline

st.set_page_config(page_title="Webè¨˜äº‹è¦ç´„ã‚¢ãƒ—ãƒª", layout="centered")
st.title("ğŸ“° Webè¨˜äº‹è¦ç´„ã‚¢ãƒ—ãƒª")

url = st.text_input("è¨˜äº‹ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šhttps://example.com/articleï¼‰")

if url:
    try:
        # è¨˜äº‹æœ¬æ–‡ã‚’å–å¾—
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        # ã‚¿ã‚¤ãƒˆãƒ« + æœ¬æ–‡ã®å–å¾—ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
        title = soup.title.string if soup.title else ""
        paragraphs = soup.find_all("p")
        article = "\n".join(p.get_text() for p in paragraphs)

        if len(article.strip()) < 200:
            st.error("è¨˜äº‹ã®æœ¬æ–‡ãŒååˆ†ã«å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.success("è¨˜äº‹æœ¬æ–‡ã‚’å–å¾—ã—ã¾ã—ãŸã€‚è¦ç´„ä¸­...")

            # è¦ç´„ï¼ˆHuggingFace Transformersï¼‰
            summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")
            summary = summarizer(article, max_length=200, min_length=60, do_sample=False)[0]['summary_text']

            st.subheader("ğŸ“ è¦ç´„çµæœ")
            st.write(summary)

    except Exception as e:
        st.error(f"è¨˜äº‹ã®å–å¾—ã¾ãŸã¯è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}")
